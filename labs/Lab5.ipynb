{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lab 5 - Spark SQL\n",
    "\n",
    "Please review Lab 4 before proceeding. For this lab we will analyze a very large dataset from the Department of Transportation. **For this lab, my advice is to use the server instead of databricks.** I only say this because I already have the data available for you. I have already converted the data to the parquet format discussed in class, but if you don't believe me that it has benefits, let's check out some stats:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the original data as I downloaded it without any modification other than I unzipped it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44G\t/disk/airline-data\r\n"
     ]
    }
   ],
   "source": [
    "!du -sh /disk/airline-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the data after I processed it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6G\t/disk/airline-data-processed\r\n"
     ]
    }
   ],
   "source": [
    "!du -sh /disk/airline-data-processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well I don't know about you, but that seems amazing :) Here is the original compressed file size. It is important to realize while the .tar.gz file is \"small\" at 4.7 GB, we can't access it with Spark or any other program without uncompressing it. But we can do that with the parquet files!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.7G\t/disk/airline-data.2003-2018.tar.gz\r\n"
     ]
    }
   ],
   "source": [
    "!du -sh /disk/airline-data.2003-2018.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are curious how I did this, please check out Setup_Lab5.ipynb. No need to run this or edit it or even look at it, but it's there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've noticed during interactions that some folks are skipping the line below. It is my fault for not explaining it. In Python when you import a file it is never reloaded even if the contents change on disk. If you run the cell below before an import, then it will reload automatically for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# make sure your run the cell above before running this\n",
    "import Lab5_helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+---------+----------+-------------+---------+-------+-------+---------+---------------+------------------+------------------+------+--------------------+-----------+---------------+---------------+---------+-------------+----------------+----------------+----+------------------+---------+-------------+-------------+-------+----------+-------+--------+---------------+--------+--------------------+----------+-------+---------+--------+------+----------+-------+--------+---------------+--------+------------------+----------+---------+----------------+--------+--------------+-----------------+-------+-------+--------+-------------+------------+------------+--------+-------------+-----------------+----+-----+\n",
      "|Quarter|DayofMonth|DayOfWeek|FlightDate|UniqueCarrier|AirlineID|Carrier|TailNum|FlightNum|OriginAirportID|OriginAirportSeqID|OriginCityMarketID|Origin|      OriginCityName|OriginState|OriginStateFips|OriginStateName|OriginWac|DestAirportID|DestAirportSeqID|DestCityMarketID|Dest|      DestCityName|DestState|DestStateFips|DestStateName|DestWac|CRSDepTime|DepTime|DepDelay|DepDelayMinutes|DepDel15|DepartureDelayGroups|DepTimeBlk|TaxiOut|WheelsOff|WheelsOn|TaxiIn|CRSArrTime|ArrTime|ArrDelay|ArrDelayMinutes|ArrDel15|ArrivalDelayGroups|ArrTimeBlk|Cancelled|CancellationCode|Diverted|CRSElapsedTime|ActualElapsedTime|AirTime|Flights|Distance|DistanceGroup|CarrierDelay|WeatherDelay|NASDelay|SecurityDelay|LateAircraftDelay|Year|Month|\n",
      "+-------+----------+---------+----------+-------------+---------+-------+-------+---------+---------------+------------------+------------------+------+--------------------+-----------+---------------+---------------+---------+-------------+----------------+----------------+----+------------------+---------+-------------+-------------+-------+----------+-------+--------+---------------+--------+--------------------+----------+-------+---------+--------+------+----------+-------+--------+---------------+--------+------------------+----------+---------+----------------+--------+--------------+-----------------+-------+-------+--------+-------------+------------+------------+--------+-------------+-----------------+----+-----+\n",
      "|      3|         7|        5|2018-09-07|           UA|    19977|     UA| N37502|     2094|          14679|           1467903|             33570|   SAN|       San Diego, CA|         CA|              6|     California|       91|        12266|         1226603|           31453| IAH|       Houston, TX|       TX|           48|        Texas|     74|      0750|   0747|    -3.0|            0.0|     0.0|                  -1| 0700-0759|   18.0|     0805|    1248|   8.0|      1256|   1256|     0.0|            0.0|     0.0|                 0| 1200-1259|      0.0|            null|     0.0|         186.0|            189.0|  163.0|    1.0|  1303.0|            6|        null|        null|    null|         null|             null|2018|    9|\n",
      "|      3|         5|        3|2018-09-05|           MQ|    20398|     MQ| N908AE|     3492|          13930|           1393006|             30977|   ORD|         Chicago, IL|         IL|             17|       Illinois|       41|        13367|         1336705|           33367| MLI|        Moline, IL|       IL|           17|     Illinois|     41|      0840|   0834|    -6.0|            0.0|     0.0|                  -1| 0800-0859|   14.0|     0848|    0915|   5.0|      0935|   0920|   -15.0|            0.0|     0.0|                -1| 0900-0959|      0.0|            null|     0.0|          55.0|             46.0|   27.0|    1.0|   139.0|            1|        null|        null|    null|         null|             null|2018|    9|\n",
      "|      3|         7|        5|2018-09-07|           UA|    19977|     UA| N69826|     2093|          11298|           1129806|             30194|   DFW|Dallas/Fort Worth...|         TX|             48|          Texas|       74|        14771|         1477104|           32457| SFO| San Francisco, CA|       CA|            6|   California|     91|      0743|   0737|    -6.0|            0.0|     0.0|                  -1| 0700-0759|   22.0|     0759|    0915|  30.0|      0934|   0945|    11.0|           11.0|     0.0|                 0| 0900-0959|      0.0|            null|     0.0|         231.0|            248.0|  196.0|    1.0|  1464.0|            6|        null|        null|    null|         null|             null|2018|    9|\n",
      "|      3|         6|        4|2018-09-06|           MQ|    20398|     MQ| N908AE|     3492|          13930|           1393006|             30977|   ORD|         Chicago, IL|         IL|             17|       Illinois|       41|        13367|         1336705|           33367| MLI|        Moline, IL|       IL|           17|     Illinois|     41|      0840|   0833|    -7.0|            0.0|     0.0|                  -1| 0800-0859|   15.0|     0848|    0920|   4.0|      0935|   0924|   -11.0|            0.0|     0.0|                -1| 0900-0959|      0.0|            null|     0.0|          55.0|             51.0|   32.0|    1.0|   139.0|            1|        null|        null|    null|         null|             null|2018|    9|\n",
      "|      3|         7|        5|2018-09-07|           UA|    19977|     UA| N14731|     2092|          10821|           1082106|             30852|   BWI|       Baltimore, MD|         MD|             24|       Maryland|       35|        12266|         1226603|           31453| IAH|       Houston, TX|       TX|           48|        Texas|     74|      0650|   0641|    -9.0|            0.0|     0.0|                  -1| 0600-0659|   11.0|     0652|    0824|   7.0|      0852|   0831|   -21.0|            0.0|     0.0|                -2| 0800-0859|      0.0|            null|     0.0|         182.0|            170.0|  152.0|    1.0|  1235.0|            5|        null|        null|    null|         null|             null|2018|    9|\n",
      "|      3|         7|        5|2018-09-07|           MQ|    20398|     MQ| N918AE|     3492|          13930|           1393006|             30977|   ORD|         Chicago, IL|         IL|             17|       Illinois|       41|        13367|         1336705|           33367| MLI|        Moline, IL|       IL|           17|     Illinois|     41|      0840|   0837|    -3.0|            0.0|     0.0|                  -1| 0800-0859|   16.0|     0853|    0926|   6.0|      0935|   0932|    -3.0|            0.0|     0.0|                -1| 0900-0959|      0.0|            null|     0.0|          55.0|             55.0|   33.0|    1.0|   139.0|            1|        null|        null|    null|         null|             null|2018|    9|\n",
      "|      3|         7|        5|2018-09-07|           UA|    19977|     UA| N838UA|     2090|          12266|           1226603|             31453|   IAH|         Houston, TX|         TX|             48|          Texas|       74|        10693|         1069302|           30693| BNA|     Nashville, TN|       TN|           47|    Tennessee|     54|      0740|   0734|    -6.0|            0.0|     0.0|                  -1| 0700-0759|   21.0|     0755|    0925|   7.0|      0944|   0932|   -12.0|            0.0|     0.0|                -1| 0900-0959|      0.0|            null|     0.0|         124.0|            118.0|   90.0|    1.0|   657.0|            3|        null|        null|    null|         null|             null|2018|    9|\n",
      "|      3|         9|        7|2018-09-09|           MQ|    20398|     MQ| N684JW|     3492|          13930|           1393006|             30977|   ORD|         Chicago, IL|         IL|             17|       Illinois|       41|        13367|         1336705|           33367| MLI|        Moline, IL|       IL|           17|     Illinois|     41|      0840|   0831|    -9.0|            0.0|     0.0|                  -1| 0800-0859|   18.0|     0849|    0915|   6.0|      0935|   0921|   -14.0|            0.0|     0.0|                -1| 0900-0959|      0.0|            null|     0.0|          55.0|             50.0|   26.0|    1.0|   139.0|            1|        null|        null|    null|         null|             null|2018|    9|\n",
      "|      3|         7|        5|2018-09-07|           UA|    19977|     UA| N38467|     2089|          14122|           1412202|             30198|   PIT|      Pittsburgh, PA|         PA|             42|   Pennsylvania|       23|        11292|         1129202|           30325| DEN|        Denver, CO|       CO|            8|     Colorado|     82|      0850|   0846|    -4.0|            0.0|     0.0|                  -1| 0800-0859|   23.0|     0909|    1008|   9.0|      1010|   1017|     7.0|            7.0|     0.0|                 0| 1000-1059|      0.0|            null|     0.0|         200.0|            211.0|  179.0|    1.0|  1290.0|            6|        null|        null|    null|         null|             null|2018|    9|\n",
      "|      3|        10|        1|2018-09-10|           MQ|    20398|     MQ| N667GB|     3492|          13930|           1393006|             30977|   ORD|         Chicago, IL|         IL|             17|       Illinois|       41|        13367|         1336705|           33367| MLI|        Moline, IL|       IL|           17|     Illinois|     41|      0840|   0834|    -6.0|            0.0|     0.0|                  -1| 0800-0859|   23.0|     0857|    0925|   4.0|      0935|   0929|    -6.0|            0.0|     0.0|                -1| 0900-0959|      0.0|            null|     0.0|          55.0|             55.0|   28.0|    1.0|   139.0|            1|        null|        null|    null|         null|             null|2018|    9|\n",
      "|      3|         7|        5|2018-09-07|           UA|    19977|     UA| N448UA|     2088|          11292|           1129202|             30325|   DEN|          Denver, CO|         CO|              8|       Colorado|       82|        14869|         1486903|           34614| SLC|Salt Lake City, UT|       UT|           49|         Utah|     87|      1127|   1126|    -1.0|            0.0|     0.0|                  -1| 1100-1159|   14.0|     1140|    1242|   6.0|      1304|   1248|   -16.0|            0.0|     0.0|                -2| 1300-1359|      0.0|            null|     0.0|          97.0|             82.0|   62.0|    1.0|   391.0|            2|        null|        null|    null|         null|             null|2018|    9|\n",
      "|      3|        11|        2|2018-09-11|           MQ|    20398|     MQ| N642AE|     3492|          13930|           1393006|             30977|   ORD|         Chicago, IL|         IL|             17|       Illinois|       41|        13367|         1336705|           33367| MLI|        Moline, IL|       IL|           17|     Illinois|     41|      0840|   0829|   -11.0|            0.0|     0.0|                  -1| 0800-0859|   12.0|     0841|    0908|   8.0|      0935|   0916|   -19.0|            0.0|     0.0|                -2| 0900-0959|      0.0|            null|     0.0|          55.0|             47.0|   27.0|    1.0|   139.0|            1|        null|        null|    null|         null|             null|2018|    9|\n",
      "|      3|         7|        5|2018-09-07|           UA|    19977|     UA| N17719|     2087|          14893|           1489302|             33192|   SMF|      Sacramento, CA|         CA|              6|     California|       91|        12266|         1226603|           31453| IAH|       Houston, TX|       TX|           48|        Texas|     74|      1255|   1249|    -6.0|            0.0|     0.0|                  -1| 1200-1259|   14.0|     1303|    1823|   3.0|      1830|   1826|    -4.0|            0.0|     0.0|                -1| 1800-1859|      0.0|            null|     0.0|         215.0|            217.0|  200.0|    1.0|  1609.0|            7|        null|        null|    null|         null|             null|2018|    9|\n",
      "|      3|        12|        3|2018-09-12|           MQ|    20398|     MQ| N663AR|     3492|          13930|           1393006|             30977|   ORD|         Chicago, IL|         IL|             17|       Illinois|       41|        13367|         1336705|           33367| MLI|        Moline, IL|       IL|           17|     Illinois|     41|      0840|   0834|    -6.0|            0.0|     0.0|                  -1| 0800-0859|   24.0|     0858|    0925|   4.0|      0935|   0929|    -6.0|            0.0|     0.0|                -1| 0900-0959|      0.0|            null|     0.0|          55.0|             55.0|   27.0|    1.0|   139.0|            1|        null|        null|    null|         null|             null|2018|    9|\n",
      "|      3|         7|        5|2018-09-07|           UA|    19977|     UA| N455UA|     2086|          14893|           1489302|             33192|   SMF|      Sacramento, CA|         CA|              6|     California|       91|        14771|         1477104|           32457| SFO| San Francisco, CA|       CA|            6|   California|     91|      0600|   0558|    -2.0|            0.0|     0.0|                  -1| 0600-0659|   18.0|     0616|    0646|   5.0|      0655|   0651|    -4.0|            0.0|     0.0|                -1| 0600-0659|      0.0|            null|     0.0|          55.0|             53.0|   30.0|    1.0|    86.0|            1|        null|        null|    null|         null|             null|2018|    9|\n",
      "|      3|        13|        4|2018-09-13|           MQ|    20398|     MQ| N694AE|     3492|          13930|           1393006|             30977|   ORD|         Chicago, IL|         IL|             17|       Illinois|       41|        13367|         1336705|           33367| MLI|        Moline, IL|       IL|           17|     Illinois|     41|      0840|   0836|    -4.0|            0.0|     0.0|                  -1| 0800-0859|   13.0|     0849|    0915|   5.0|      0935|   0920|   -15.0|            0.0|     0.0|                -1| 0900-0959|      0.0|            null|     0.0|          55.0|             44.0|   26.0|    1.0|   139.0|            1|        null|        null|    null|         null|             null|2018|    9|\n",
      "|      3|         7|        5|2018-09-07|           UA|    19977|     UA| N854UA|     2085|          12266|           1226603|             31453|   IAH|         Houston, TX|         TX|             48|          Texas|       74|        13495|         1349505|           33495| MSY|   New Orleans, LA|       LA|           22|    Louisiana|     72|      2013|   2032|    19.0|           19.0|     1.0|                   1| 2000-2059|   25.0|     2057|    2141|   2.0|      2121|   2143|    22.0|           22.0|     1.0|                 1| 2100-2159|      0.0|            null|     0.0|          68.0|             71.0|   44.0|    1.0|   305.0|            2|        19.0|         0.0|     3.0|          0.0|              0.0|2018|    9|\n",
      "|      3|        14|        5|2018-09-14|           MQ|    20398|     MQ| N931AE|     3492|          13930|           1393006|             30977|   ORD|         Chicago, IL|         IL|             17|       Illinois|       41|        13367|         1336705|           33367| MLI|        Moline, IL|       IL|           17|     Illinois|     41|      0840|   0909|    29.0|           29.0|     1.0|                   1| 0800-0859|   18.0|     0927|    0955|   3.0|      0935|   0958|    23.0|           23.0|     1.0|                 1| 0900-0959|      0.0|            null|     0.0|          55.0|             49.0|   28.0|    1.0|   139.0|            1|        23.0|         0.0|     0.0|          0.0|              0.0|2018|    9|\n",
      "|      3|         7|        5|2018-09-07|           UA|    19977|     UA| N15710|     2082|          14057|           1405702|             34057|   PDX|        Portland, OR|         OR|             41|         Oregon|       92|        12266|         1226603|           31453| IAH|       Houston, TX|       TX|           48|        Texas|     74|      0500|   0451|    -9.0|            0.0|     0.0|                  -1| 0001-0559|   14.0|     0505|    1042|   3.0|      1057|   1045|   -12.0|            0.0|     0.0|                -1| 1000-1059|      0.0|            null|     0.0|         237.0|            234.0|  217.0|    1.0|  1825.0|            8|        null|        null|    null|         null|             null|2018|    9|\n",
      "|      3|        16|        7|2018-09-16|           MQ|    20398|     MQ| N652RS|     3492|          13930|           1393006|             30977|   ORD|         Chicago, IL|         IL|             17|       Illinois|       41|        13367|         1336705|           33367| MLI|        Moline, IL|       IL|           17|     Illinois|     41|      0840|   0832|    -8.0|            0.0|     0.0|                  -1| 0800-0859|   23.0|     0855|    0921|   5.0|      0935|   0926|    -9.0|            0.0|     0.0|                -1| 0900-0959|      0.0|            null|     0.0|          55.0|             54.0|   26.0|    1.0|   139.0|            1|        null|        null|    null|         null|             null|2018|    9|\n",
      "+-------+----------+---------+----------+-------------+---------+-------+-------+---------+---------------+------------------+------------------+------+--------------------+-----------+---------------+---------------+---------+-------------+----------------+----------------+----+------------------+---------+-------------+-------------+-------+----------+-------+--------+---------------+--------+--------------------+----------+-------+---------+--------+------+----------+-------+--------+---------------+--------+------------------+----------+---------+----------------+--------+--------------+-----------------+-------+-------+--------+-------------+------------+------------+--------+-------------+-----------------+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Our main data source\n",
    "on_time_df = spark.read.parquet('file:///disk/airline-data-processed/airline-data.parquet')\n",
    "on_time_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is a bit brutal to look at... Consider examining like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Quarter',\n",
       " 'DayofMonth',\n",
       " 'DayOfWeek',\n",
       " 'FlightDate',\n",
       " 'UniqueCarrier',\n",
       " 'AirlineID',\n",
       " 'Carrier',\n",
       " 'TailNum',\n",
       " 'FlightNum',\n",
       " 'OriginAirportID',\n",
       " 'OriginAirportSeqID',\n",
       " 'OriginCityMarketID',\n",
       " 'Origin',\n",
       " 'OriginCityName',\n",
       " 'OriginState',\n",
       " 'OriginStateFips',\n",
       " 'OriginStateName',\n",
       " 'OriginWac',\n",
       " 'DestAirportID',\n",
       " 'DestAirportSeqID',\n",
       " 'DestCityMarketID',\n",
       " 'Dest',\n",
       " 'DestCityName',\n",
       " 'DestState',\n",
       " 'DestStateFips',\n",
       " 'DestStateName',\n",
       " 'DestWac',\n",
       " 'CRSDepTime',\n",
       " 'DepTime',\n",
       " 'DepDelay',\n",
       " 'DepDelayMinutes',\n",
       " 'DepDel15',\n",
       " 'DepartureDelayGroups',\n",
       " 'DepTimeBlk',\n",
       " 'TaxiOut',\n",
       " 'WheelsOff',\n",
       " 'WheelsOn',\n",
       " 'TaxiIn',\n",
       " 'CRSArrTime',\n",
       " 'ArrTime',\n",
       " 'ArrDelay',\n",
       " 'ArrDelayMinutes',\n",
       " 'ArrDel15',\n",
       " 'ArrivalDelayGroups',\n",
       " 'ArrTimeBlk',\n",
       " 'Cancelled',\n",
       " 'CancellationCode',\n",
       " 'Diverted',\n",
       " 'CRSElapsedTime',\n",
       " 'ActualElapsedTime',\n",
       " 'AirTime',\n",
       " 'Flights',\n",
       " 'Distance',\n",
       " 'DistanceGroup',\n",
       " 'CarrierDelay',\n",
       " 'WeatherDelay',\n",
       " 'NASDelay',\n",
       " 'SecurityDelay',\n",
       " 'LateAircraftDelay',\n",
       " 'Year',\n",
       " 'Month']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "on_time_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Quarter=3, DayofMonth=7, DayOfWeek=5, FlightDate=datetime.date(2018, 9, 7), UniqueCarrier='UA', AirlineID=19977, Carrier='UA', TailNum='N37502', FlightNum=2094, OriginAirportID=14679, OriginAirportSeqID=1467903, OriginCityMarketID=33570, Origin='SAN', OriginCityName='San Diego, CA', OriginState='CA', OriginStateFips=6, OriginStateName='California', OriginWac=91, DestAirportID=12266, DestAirportSeqID=1226603, DestCityMarketID=31453, Dest='IAH', DestCityName='Houston, TX', DestState='TX', DestStateFips=48, DestStateName='Texas', DestWac=74, CRSDepTime='0750', DepTime='0747', DepDelay=-3.0, DepDelayMinutes=0.0, DepDel15=0.0, DepartureDelayGroups=-1, DepTimeBlk='0700-0759', TaxiOut=18.0, WheelsOff='0805', WheelsOn='1248', TaxiIn=8.0, CRSArrTime='1256', ArrTime='1256', ArrDelay=0.0, ArrDelayMinutes=0.0, ArrDel15=0.0, ArrivalDelayGroups=0, ArrTimeBlk='1200-1259', Cancelled=0.0, CancellationCode=None, Diverted=0.0, CRSElapsedTime=186.0, ActualElapsedTime=189.0, AirTime=163.0, Flights=1.0, Distance=1303.0, DistanceGroup=6, CarrierDelay=None, WeatherDelay=None, NASDelay=None, SecurityDelay=None, LateAircraftDelay=None, Year=2018, Month=9)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The first row\n",
    "on_time_df.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if you want to average AirTime?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|    avg(AirTime)|\n",
      "+----------------+\n",
      "|106.840895516509|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg, col\n",
    "\n",
    "on_time_df.select('AirTime').agg(\n",
    "    avg(col('AirTime'))\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we need navigate a fine line where I don't throw the entire Spark SQL api at you, but there are some functions above that should be discussed. The first is select which you can use to get a subset of the columns. This is important for memory usage. Load only what you need :). The next few are agg which is short for aggregate. Then there is col which selects the column and then avg which of course is average. If you know sql, you can also rely on SQL to work the magic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|    avg(AirTime)|\n",
      "+----------------+\n",
      "|106.840895516509|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "on_time_df.select('AirTime').createOrReplaceTempView(\"AirTimeView\") # create a temporary view so we can query our data\n",
    "\n",
    "sqlDF = spark.sql(\"SELECT avg(AirTime) FROM AirTimeView\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't know about you, but since I already know SQL or at least some SQL, I'm very excited that I can use that. For this lab in general, please use what makes sense to you to accomplish the job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if I wanted average air time per month?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+\n",
      "|Month|      avg(AirTime)|\n",
      "+-----+------------------+\n",
      "|   12| 108.9605027894764|\n",
      "|    1|106.82890250362068|\n",
      "|    6|106.96005748333293|\n",
      "|    3|108.13478826356425|\n",
      "|    5|106.01523155420969|\n",
      "|    9|105.11722965450537|\n",
      "|    4|106.98955608533186|\n",
      "|    8|106.53259036679218|\n",
      "|    7|107.72642114700079|\n",
      "|   10|105.03766685659184|\n",
      "|   11|106.60017004471732|\n",
      "|    2|107.08287579839748|\n",
      "+-----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "on_time_df.select('AirTime','Month').createOrReplaceTempView(\"AirTimeView\") # create a temporary view so we can query our data\n",
    "\n",
    "sqlDF = spark.sql(\"SELECT Month, avg(AirTime) FROM AirTimeView group by Month\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+\n",
      "|Month|      avg(AirTime)|\n",
      "+-----+------------------+\n",
      "|   12| 108.9605027894764|\n",
      "|    1|106.82890250362068|\n",
      "|    6|106.96005748333293|\n",
      "|    3|108.13478826356425|\n",
      "|    5|106.01523155420969|\n",
      "|    9|105.11722965450537|\n",
      "|    4|106.98955608533186|\n",
      "|    8|106.53259036679218|\n",
      "|    7|107.72642114700079|\n",
      "|   10|105.03766685659184|\n",
      "|   11|106.60017004471732|\n",
      "|    2|107.08287579839748|\n",
      "+-----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "on_time_df.select('AirTime','Month').groupBy(\n",
    "    'Month'\n",
    ").agg(\n",
    "    avg(col('AirTime'))\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty nice right? You can see why companies might really value engineers who can bring data processing skills with them.\n",
    "\n",
    "Let's now read in some data that helps us map Carrier name to AirlineName."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines = spark.read.parquet('file:///disk/airline-data/DOT_airline_codes_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-------+\n",
      "|AirlineID|         AirlineName|Carrier|\n",
      "+---------+--------------------+-------+\n",
      "|    19031|Mackey Internatio...|    MAC|\n",
      "|    19032|Munz Northern Air...|     XY|\n",
      "|    19033|Cochise Airlines ...|    COC|\n",
      "|    19034|Golden Gate Airli...|    GSA|\n",
      "|    19035|       Aeromech Inc.|    RZZ|\n",
      "|    19036|Golden West Airli...|    GLW|\n",
      "|    19037|Puerto Rico Intl ...|    PRN|\n",
      "|    19038|    Air America Inc.|    STZ|\n",
      "|    19039|Swift Aire Lines ...|    SWT|\n",
      "|    19040|American Central ...|    TSF|\n",
      "|    19041|     Valdez Airlines|    VEZ|\n",
      "|    19042|Southeast Alaska ...|    WEB|\n",
      "|    19043|Altair Airlines Inc.|    AAR|\n",
      "|    19044| Chitina Air Service|    CHI|\n",
      "|    19045|Marco Island Airw...|    MRC|\n",
      "|    19046|Caribbean Air Ser...|    OHZ|\n",
      "|    19047|   Sundance Airlines|    PRO|\n",
      "|    19048|Seair Alaska Airl...|    SAI|\n",
      "|    19049|Southeast Airline...|    SLZ|\n",
      "|    19050|Alaska Aeronautic...|    AAZ|\n",
      "+---------+--------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airlines.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want to apply a user defined function? Here is an example where a new function is defined that combines Year and Month into a string. I also use the sample function to illustrate how to get a random subset of the data. Finally, I show an important function called ``cache``. It is important because we may want to reuse a result. Cache tells Spark that we want to reuse something so please try to keep it cached for us. Finally, I show how you can use orderBy to sort the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "def getYearMonthStr(year, month):\n",
    "    return '%d-%02d'%(year,month)\n",
    "\n",
    "udfGetYearMonthStr = udf(getYearMonthStr, StringType())\n",
    "\n",
    "example1 = on_time_df.select('Year','Month').withColumn(\n",
    "    'YearMonth', udfGetYearMonthStr('Year','Month')).sample(0.000001).cache()\n",
    "\n",
    "example1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example1.orderBy('YearMonth').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, there are a number of things to make the world go round, such as renaming a column:\n",
    "```python\n",
    "df.withColumnRenamed(\"dob\",\"DateOfBirth\").printSchema()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1:** Create a dataframe that contains the average delay for each airline:\n",
    "* Columns: Carrier, average_delay, YearMonth\n",
    "* Carrier must be one of the following: 'AA','WN','DL','UA','MQ','EV','AS','VX'\n",
    "* Must be ordered by YearMonth, Carrier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_delay = Lab5_helper.exercise_1(on_time_df)\n",
    "## BEGIN ANSWER\n",
    "answers['exercise_1'] = airline_delay.head(10)\n",
    "## END ANSWER\n",
    "airline_delay.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2:** Now add a column with the airline name (i.e., use a join). Here is an example from the Spark documentation.\n",
    "\n",
    "```python\n",
    "# To create DataFrame using SparkSession\n",
    "people = spark.read.parquet(\"...\")\n",
    "department = spark.read.parquet(\"...\")\n",
    "\n",
    "people.filter(people.age > 30).join(department, people.deptId == department.id) \\\n",
    "  .groupBy(department.name, \"gender\").agg({\"salary\": \"avg\", \"age\": \"max\"})\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_delay2 = Lab5_helper.exercise_2(airline_delay,airlines)\n",
    "## BEGIN ANSWER\n",
    "answers['exercise_2'] = airline_delay2.head(10)\n",
    "## END ANSWER\n",
    "airline_delay2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you did everything correctly, you are now rewarded with a nice graph :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "airline_delay_pd = airline_delay2.toPandas()\n",
    "\n",
    "import altair as alt\n",
    "\n",
    "alt.Chart(airline_delay_pd).mark_line().encode(\n",
    "    x='YearMonth',\n",
    "    y='average_delay',\n",
    "    color='AirlineName'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3:** Let's assume you believe that the delays experienced by some airlines are correlated. The cause is a different story as we all know correlation does not equal causation. But correlation is often what we can easily calculate, so let's do it on a month by month basis. The first step is of course to get the data in the correct format. We would like each airline to have it's own column because we can easily compute the correlation between columns. Each row in this new dataframe should be a YearMonth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_corr = Lab5_helper.exercise_3(airline_delay2)\n",
    "## BEGIN ANSWER\n",
    "answers['exercise_3'] = data_for_corr.toPandas()\n",
    "## END ANSWER\n",
    "\n",
    "# The data is now small enough to handle, so let's get it into pandas and calculate the correlation and filling\n",
    "# in missing values with the mean of the column\n",
    "\n",
    "df = data_for_corr.toPandas().set_index('YearMonth')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp_mean.fit(df)\n",
    "\n",
    "df_imputed_nan = pd.DataFrame(imp_mean.transform(df),columns=df.columns,index=df.index)\n",
    "df_imputed_nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look at the correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed_nan.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anything stand out to you? Let me clean it up and sort it for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs = df_imputed_nan.corr()\n",
    "corrs.values[np.tril_indices(len(corrs))] = np.NaN \n",
    "corrs.stack().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good job!\n",
    "# Don't forget to push with ./submit.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,md,py"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
